\documentclass{article}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{indentfirst}   % Indents first paragraph. change if u want ig
\usepackage{setspace}
\usepackage{qtree}
\doublespacing

\begin{document}
\title{\textbf{The Master Theorem}}
\author{Remington Greko, Tyler Gutowski, and Spencer Hirsch}
\date{\today}

\maketitle

\noindent Work with your team to write a report about the \textit{Master Theorem} for solving
a recurrence.

I've usually avoided the \textit{Master Theorem} because it has too many rules and does not
offer real insight to the solution of the recurrene. However, I do include it in my handouts
and the \textit{Master Therorem} may be useful for find the solution to \textit{Strassen's
matrix multiplication recurrence.}

\[T(n) = 7T(n/2) + O(n^2)\]

\noindent There are many details beneath this recurrence. I strongly encourage you to read
what is in the Corman textbook and other sources.

Submit the team's report on Canvas. Include a task matric indicating who did what.

\pagebreak

\noindent \textbf{\href{https://en.wikipedia.org/wiki/Master_theorem_(analysis_of_algorithms)}{Wikipedia Summary of the Master Theorem}}

In 1980, the Master Theorem was proposed as the "unifying method" for solving recurrences by Jon Bentley, Dorothea Blostein, and James B. Saxe.\footnote{Wikipedia.}
Although the name may imply it can solve all recurrences, this is not the case, it's a generalized theory that may be helpful in
solving recurrence relations. The Master Theorem utilizes a divide and conquer approach with allows it to separate processing into
numerous parts. The master theorem can be expressed by adding the time taken by the top level process with the time made with the recursive
calls of the algorithm.\footnote{Id.} The algorithm for the recurrence relation is expressed as:\footnote{Id.}

\[T(n) + aT(n/b) + f(n)\]

\noindent Where, n is the input size, a is the number of subproblems, and b is the factor by which the size is reduced.\footnote{Id.} It can be determined
based on the Theorem the best case time complexity of the Master Theorem is constant time or \textit{O(1)}.

\bigskip

\bigskip

\noindent \textbf{\href{https://brilliant.org/wiki/master-theorem/}{Brilliant Article on the Master Theorem}}

\textit{Statement of the Master Theorem} \\

Given the algorithm listed above, the runtime of each of the initial nodes is the runtime of T(n/b). Therefore the depth of the tree 
is $log_bn$ with the depth \textit{i} has \textit{$a^i$} nodes in that final level.\footnote{Brilliant} Therefore,

\[a^{log_bn} = n^{log_bn}\]

which demonstrates the the runtime of the program is \textit{$O(n^{log_ba})$}.\footnote{Id.} Through this reasoning
you can determine that the form of \textit{T} is based between \textit{f} and \textit{$n^{log_ba}$}.\footnote{Id.}

\pagebreak

\textit{The Master Theorem Itself} \\
Given the previous form listed in the Wikipedia section, with constants \textit{$a\geq1$} and \textit{$b>1$} with \textit{f}.\footnote{Id.}\\
The follwing are true: \\
\begin{quote}
``\noindent \textit{$f(n) = O(n^{log_ba-\epsilon})$} for some $\epsilon > 0$, then \textit{$T(n) = O(n^{log_ba})$}. \\
\textit{$f(n) = O(n^{log_ba})$}, then \textit{$T(n) = O(n^{log_ba}logn)$}.\\
\textit{$f(n) = O(n^{log_ba+\epsilon})$} for some $\epsilon > 0$, then \textit{T(n) = O(f(n))}.'' \footnote{Id.}
\end{quote}

\noindent \textbf{Cormen Discussion of the Master Theorem}

\smallskip

Cormen describes the master theorem as a "cookbook" method for solving recurrences which are in the form \textit{$T(n) = aT(n/b) + f(n)$}.
This equation represents the running time of an algorithm which is divided into \textit{$n$} subproblems, sized \textit{$n/b$}, where \textit{$n$} 
and \textit{$b$} are positive constants. Each subproblem \textit{$a$} is solved recursived in time \textit{$T(n/b)$} and the cost of dividing the
problem is described by \textit{$f(n)$}. 

\bigskip

\noindent\textit{The Master Theorem}

\smallskip

\noindent{The master theorem itself is as follows:}

\smallskip

Let \textit{$a\geq 1$} and \textit{$b > 1$} be constants, let \textit{$f(n)$} be a function, and let \textit{$T(n)$} be defined on the nonnegative
integers by the recurrence \textit{$T(n) = aT(n/b) + f(n)$}. Then \textit{$T(n)$} can be bounded asymptotically as follows.

\smallskip

\begin{enumerate}
    \item If \textit{$f(n) = O(n^{log_{b}a-\in})$} for some constant \textit{$\in > 0$}, then \textit{$T(n) = \Theta(n^{log_{b}a})$}.
    
    \item If \textit{$f(n) = \Theta(n^{log_{b}a})$}, then \textit{$T(n) = \Theta(n^{log_{b}a}lg(n))$}.
    
    \item If \textit{$f(n) = \Omega(n^{log_{b}a+\in})$} for some constant \textit{$\in > 0$}, and if \textit{$a f(n/b) /le c f(n)$} for some constant
    \textit{$c < 1$} and all sufficiently large \textit{$n$}, then \textit{$T(n) = \Theta(f(n))$}.

\end{enumerate}

\smallskip

\noindent Essentially this expresses the solution to a recurrence through comparing the function \textit{$f(n)$} with the function \textit{$n^{log_{b}a}$}.
Whichever of the two functions is larger is the solution. The first case requires that the expression \textit{$f(n)$} must be \textit{polynomially} smaller
than \textit{$n^{log_{b}a}$}. This is the same in case three where \textit{$f(n)$} must be polynomially \textit{larger} than \textit{$n^{log_{b}a}$}. 
The three cases do not cover all possibilites for \textit{$f(n)$}, there is a gap between cases 1 and 2 when \textit{$f(n)$} is smaller than 
\textit{$n^{log_{b}a}$} but not polynomially. This occurs again between 2 and 3 where \textit{$f(n)$} is not polynomially larger. In the cases where
\textit($f(n)$) falls between these cases, the master theorem cannot be used to solve the recurrence.

\bigskip

\noindent\textit{Master Theorem Example}

To use the master theorem we first determine which case applies to the given equation. For example consider:

\smallskip

\textit{$T(n) = 9T(n/3) + n$}

\smallskip

\noindent In this recurrence we have \textit{$a = 9, b = 3, f(n) = n$}, and thus \textit{$n^{log_{b}a} = n^{log_{3}9} = \Theta(n^2)$}. Since 
\textit{$f(n) = O(n^{log_{3}9 - \in})$}, where \textit{$\in = 1$}, we can apply case 1 of the master theorem. This produces the solution
\textit{$T(n) = \Theta(n^2)$}

\pagebreak
\section{Works Cited}

``Master Theorem (Analysis of Algorithms).'' Wikipedia. Wikimedia Foundation, January 31, 2023. $https://en.wikipedia.org/wiki/Master_theorem_(analysis_of_algorithms)$.

``Master Theorem.'' Brilliant Math \&amp; Science Wiki. Accessed February 28, 2023. $https://brilliant.org/wiki/master-theorem/$. 

\pagebreak

\begin{center}
        \begin{tabular}{|p{3cm}|p{6cm}|}
            \hline
            \textbf{Name} & \textbf{Section} \\
            \hline
            Remington Greko & Cormen Summary\\
            \hline
            Tyler Gutowski & \\
            \hline
            Spencer Hirsch & Read Wikipedia Article and Brilliant Article \\
            \hline
        \end{tabular}
    \end{center}

\end{document}